{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97155f7-c705-42c1-81c3-1a5a02f07706",
   "metadata": {},
   "source": [
    "# Course Project: Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582de0a-9a83-47fe-9478-cb884e1e4e67",
   "metadata": {},
   "source": [
    "In this project you will segment neurons in an electron microscope image. You will be given an electron microscope image where a neuron is stained using dense metal precipitates, and your task is to find the approximate outline of the neuron using a sequence of image processing operations that you will implement yourself.\n",
    "\n",
    "Don't worry if this seems daunting at first, you will develop the solution step by step using small building blocks, and the project progresses at the same pace as the course. During the course you will have time to work on the project and ask questions, and you can already start programming after the first day!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b249e730-00c0-4378-ae42-301e0648fe4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d24d8c-dedf-4999-8f53-bb9223e256ee",
   "metadata": {},
   "source": [
    "## Software prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1c1e0-639b-47da-b468-4b1b6c8750a3",
   "metadata": {},
   "source": [
    "This project operates on image data and we will use the following two libraries for functionality not related to the image segmentation itself:\n",
    "\n",
    "- [Pillow](https://pillow.readthedocs.io/), for reading image files into memory\n",
    "- [matplotlib](https://matplotlib.org/), for displaying images in this notebook\n",
    "\n",
    "Please ask your instructors for help with installing these libraries with Anaconda Navigator or with the `pip` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eafb53e-ac43-4d99-9453-406031bab254",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4589b8f-66c6-47d0-871e-64a951fab84d",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf585bf-a580-4caf-9f93-22f40896bf06",
   "metadata": {},
   "source": [
    "A typical analysis task after acquiring microscope images is isolating the structures of interest in the image. This *segmentation* task often  requires user interaction making it time-consuming and error-prone, especially since modern high-end microscopes can easily acquire hundreds of such images in an automated fashion in order to image a 3D volume of a sample. It is thus desirable to have an algorithm to perform this segmentation faster and in a more reproducible fashion.\n",
    "\n",
    "In this project we will develop an algorithm to segment electron microscopy (EM) images which were stained using the [Golgi staining](https://www.nature.com/articles/s41598-018-37377-x.pdf) technique, where a random neuron is stained with dense metal precipitates. On the EM images these precipitates show up as dark dots inside the neuron. Our goal is to implement a series of image processing steps that detect these dots and group them into larger regions that approximate the shape of the neuron. The figure below shows the input image on the left with the dense black precipitates, and the desired segmentation on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a3d7e-e472-424f-88c6-57224de545e0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/segm_golgi_stained_em_image.png\" width=\"250\"/>\n",
    "<img src=\"images/segm_arrow_segment.png\" width=\"40\"/>\n",
    "<img src=\"images/segm_golgi_stained_em_image_segmented.png\" width=\"250\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978ca4a-68b6-4401-84f3-14334d6a088b",
   "metadata": {},
   "source": [
    "Image processing is a very rich field with a large variety of algorithms and techniques. Here, we will focus on one branch of image processing called [mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology) and its morphological filtering operations. Morphological filtering concentrates on the geometric structure within images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c57e6-6858-416e-9ac4-f6a42be79316",
   "metadata": {},
   "source": [
    "The basic idea is to probe an image with a *structuring element* and to quantify the manner in which the structuring element fits or does not fit within the image. For example, in the figure below we have a binary image (a) and a square structuring element (b), the probe. In some locations the probe fits inside the black object, and in other places it does not. By finding the locations at which the structuring element fits, we derive structural information concerning the object in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173755bc-00f6-4e8b-a7d8-b621d7d72d7b",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_morphology_probing.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c3bad-bff2-4458-97e3-a3cfe58e6dfe",
   "metadata": {},
   "source": [
    "In the microscope image above one can imagine sliding a circular probe over the image and recording where in the image the probe overlaps with  black particles. This will fill in the gaps between nearby dots, in essence performing a rough segmentation. This idea will be refined below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae69af1-37b2-4fca-ba2b-2ba28e472bb3",
   "metadata": {},
   "source": [
    "The morphological filtering operations that we will program will all operate on binary images (\"black and white\"). The 4 basic morphological filtering operations are *erosion*, *dilation*, *opening* and *closing*. We will implement three of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26da522-1d77-4308-bc7a-73c5a58a0214",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f9241-6872-469f-9e25-4742e919595a",
   "metadata": {},
   "source": [
    "## Part 1: Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73764d09-9b1b-4839-9773-e00bea7f3e16",
   "metadata": {},
   "source": [
    "As a gentle warm-up exercise, let's look at image thresholding first. Our electron microscope image is a grayscale image, with, say, 256 or 4096 possible intensity values per pixel. For the segmentation task however we only care about the very dark particles in that image. They have pixel intensities near 0. In Part 2 of this project we will write a function that takes an image and returns an new image with only these dense particles and no other 'background'. To do so, we need to determine for each pixel whether or not its intensity is below a certain small threshold value. If it is, the pixel is likely part of the dense particle, if its intensity is higher it is probably not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0316763-6d06-4964-b3c9-b0822becb527",
   "metadata": {},
   "source": [
    "Let's solve part of this problem already. Your assignment is to write a function `is_below(val, threshold)` where `val` is the intensity of a pixel, and `threshold` is the threshold intensity of dark particles. The function should return True if the pixel intensity is below the threshold, and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60df65-b2ce-49d8-902c-6cf7de45ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def is_below_threshold(val, threshold):\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72913a69-a431-4d9e-a131-c1723e54895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_below(0, 0) == False, 'Expected: False, got: ' + str(is_below(0, 0))\n",
    "assert is_below(42, 666) == True, 'Expected: True, got: ' + str(is_below(42, 666))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2049f-6d7c-40ef-bd35-df3c9a2d7ec5",
   "metadata": {},
   "source": [
    "Great! Now that we know all about Python functions ;-) let's write a somewhat more useful one. Later in this project we will have to create an image of a disk: all pixels inside or on a circle with a given radius will have to be set to one color, and pixels outside the circle to another color. In order to do so, we will need a function that tells us whether a given pixel is inside a disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b5fff-7293-4a89-8046-66f28fe1660e",
   "metadata": {},
   "source": [
    "Hence your second assigment is to write a function `is_inside_disk(x, y, radius)` which returns True if the point $(x, y)$ is inside or on a circle with center at $(0,0)$ and with given `radius`, and which returns False otherwise. Remember, the distance from a point with coordinates $(x, y)$ to the origin $(0, 0)$ is given by $\\sqrt{x^2 + y^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3d9b4-5b02-4f82-b45f-9f93ffe64a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def is_inside_disk(x, r, radius):\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28293226-d0b1-433e-901e-77ad096c30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_inside_disk(0, 0, 0) == True, 'Expected: True, got: ' + str(is_inside_disk(0, 0, 0))\n",
    "assert is_inside_disk(1, 0, 0) == False, 'Expected: False, got: ' + str(is_inside_disk(1, 0, 0))\n",
    "assert is_inside_disk(3, 4, 5) == True, 'Expected: True, got: ' + str(is_inside_disk(3, 4, 5))  # exactly on the disk is considered inside\n",
    "assert is_inside_disk(1, 1, 2) == True, 'Expected: True, got: ' + str(is_inside_disk(1, 1, 2))\n",
    "assert is_inside_disk(1, 1, 1) == False, 'Expected: False, got: ' + str(is_inside_disk(1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04786244-4614-4ac4-be24-4d362b9aceb1",
   "metadata": {},
   "source": [
    "Fantastic! That's all for part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf6a1d-4a81-4624-94d5-af4bcf3dac59",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37640da8-9b37-4277-aa2d-1d10547f49aa",
   "metadata": {},
   "source": [
    "## Part 2: Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe235d3-8595-44ae-8f3f-381abed1aac7",
   "metadata": {},
   "source": [
    "### Data structure for images and structuring elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6196b-061e-4fdc-a289-3e89a516f88e",
   "metadata": {},
   "source": [
    "One of the most important decisions in any programming task is deciding on what data structures to use to represent the objects that need to be manipulated. In this project these objects are the images and the structuring elements (which are basically also images) that operate on them.\n",
    "\n",
    "For \"real-life\" programming tasks on common objects such as images, it is very much advisable to use data structures offered by solid, well-tested Python libraries instead of rolling your own. However, often these libraries require some time to become proficient with them, and in the context of this course we will nevertheless devise our *own* simple image data structure instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae0f3fa-032b-41f1-9c3d-0d21f2bc2b1a",
   "metadata": {},
   "source": [
    "An image can be viewed as a rectangular matrix of values of pixel intensities. We will represent an image in Python as a list of rows of pixels, and each row as a list of pixel intensity values. So an image will be a list of lists. Suppose we have an image `img` in such a representation. The intensity value of the pixel in the i-th row and the j-th column in the image `img`, is obtained by first retrieving the i-th row in `img`, which is `img[i]`, and then accessing the j-th element in that list, which yields `img[i][j]`. This is illustrated below, with an image with 5 rows and  columns on the left, and its Python representation as a list of lists (with dummy elements) on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4cd5d3-af8a-43db-acf4-eeddfb8aa1ee",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_image_representation.jpg\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea43038-1465-4230-807f-28a2708e6d23",
   "metadata": {},
   "source": [
    "### Grayscale and binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5ccdd-099c-4779-8c7a-623f5b10862e",
   "metadata": {},
   "source": [
    "In this project we will deal with both 8-bit per pixel grayscale images (with pixel values ranging from 0 to 255), and binary images (with pixels values 0 or 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54253339-0fe7-4fd3-9bb7-247e6061ce5d",
   "metadata": {},
   "source": [
    "*By convention, the value 0 in a grayscale image is displayed as black, 255 as white, and values in between as increasingly bright grays.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa954d1-b973-4d3d-a722-e2ccc58f3e1d",
   "metadata": {},
   "source": [
    "*For our binary images we adopt the convertion that the value 0 is shown as white and represents the empty background, whereas the value 1 will be shown as a black pixel and will represent the presence of an object in the image.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3f8c8-3e44-4509-a77e-efa5a63807a4",
   "metadata": {},
   "source": [
    "For your convenience we provide the function `viz(img)` which accepts an image in the representation discussed above (list of lists) and displays it in this notebook. For binary images (which is what we will use most of the time) you can simply pass the image to `viz` for displaying. For grayscale images we do however need to pass the additional named argument `is_binary=False` to signal `viz` that it needs to use the color convention for grayscale images. Don't worry if this confuses you a bit, we normally have provided visualization code for you already in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7cbe25-38c7-4686-94b3-1dba511e880c",
   "metadata": {},
   "source": [
    "Let's now define a grayscale image and a binary image and demonstrate how to display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d1662-d71b-4689-aee6-345e1cfb1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function viz() for displaying images in our representation.\n",
    "%matplotlib inline\n",
    "from solutions.segmentation import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c2777-4cab-43de-89f2-9b815232ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A grayscale image with 3 rows and 4 columns\n",
    "img = [[0, 100, 255, 200],\n",
    "       [20, 210, 107, 203],\n",
    "       [255, 240, 0, 190]]\n",
    "viz(img, is_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9a03f-3db7-41c0-bc22-11e42cde2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A binary image with 3 rows and 4 columns\n",
    "img = [[0, 1, 1, 0],\n",
    "       [0, 1, 0, 1],\n",
    "       [1, 1, 0, 1]]\n",
    "viz(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c1245-72da-4242-8e92-567e0542d091",
   "metadata": {},
   "source": [
    "Note how the value 0 is rendered as black in the grayscale image, and was white in the binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63458aca-43ff-4766-a598-a51bd83ab359",
   "metadata": {},
   "source": [
    "### Image dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378ed6b-1342-45c5-91a5-593251bdcdda",
   "metadata": {},
   "source": [
    "With all this out of the way we can finally do some more coding! Our first assignment with images is writing a function which finds the dimensions of a given image: given an image `img`, write a function `get_dimensions(img)` which returns a pair `(height, width)` where height is the number of rows, and width the number of columns in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31602cf9-8e79-43f3-a1bc-4e91f4557807",
   "metadata": {},
   "source": [
    "For robustness we will also handle the case of an image without any pixels at all, so with 0 rows and 0 columns. Such a singular image is represented as `[]`. Edge cases are a common source of bugs in programs, so it's important to pay attention to them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd78198-d9b2-4d44-8e27-db3156ec270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def get_image_dimensions(img):\n",
    "    height = _\n",
    "    if height > 0:\n",
    "        width = _\n",
    "    else:\n",
    "        width = _\n",
    "    return height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ed90d-bd9a-48ca-ba6c-b382ac21a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_image_dimensions([]) == (0, 0)  # edge case, an image without any pixels\n",
    "assert get_image_dimensions([[0]]) == (1, 1)\n",
    "assert get_image_dimensions([[0, 1]]) == (1, 2)\n",
    "assert get_image_dimensions([[0], [1]]) == (2, 1)\n",
    "assert get_image_dimensions([[0, 0, 0, 0, 0], [1, 2, 3, 4, 5]]) == (2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ccdc3-3d33-4c52-95fe-c676a919be1d",
   "metadata": {},
   "source": [
    "### Creating an empty image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af8e36-cd31-4ddc-8df9-274cea089f04",
   "metadata": {},
   "source": [
    "For several image operations later in the project it will be convenient if we have a function for constructing \"empty\" images, so images filled with the pixel intensity of the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe5dd0-9db9-455f-8e64-62cbdc5548cb",
   "metadata": {},
   "source": [
    "Write a function `make_empty_image(height, width)` which constructs an image with `height` rows and `width` columns, and where each pixel is set to the value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421d9f7-5185-4fa4-acde-bbcb3c7e972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def make_empty_image(height, width):\n",
    "    img = []\n",
    "    for i in range(height):\n",
    "        row = []\n",
    "        # ADD CODE HERE: fill in empty pixels in row\n",
    "        img.append(row)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2e410-a723-4563-b522-124b4bf095ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert make_empty_image(0, 0) == [], 'Expected: [], got: ' + str(make_empty_image(0, 0))\n",
    "assert make_empty_image(1, 1) == [[0]], 'Expected: [[0]], got: ' + str(make_empty_image(1, 1))\n",
    "assert make_empty_image(2, 5) == [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'Expected: [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], got: ' + str(make_empty_image(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a0764-1c53-47c0-b1d5-2527eb352531",
   "metadata": {},
   "source": [
    "Let's vizualize the output of `make_empty_image()` to confirm that everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e276975-1338-4726-af2e-8658fd374c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = make_empty_image(4, 6)\n",
    "viz(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42676fd8-d141-49cc-959c-6b5e1fd2d291",
   "metadata": {},
   "source": [
    "Okay, that looks like an array of empty pixels to me! Not totally stunning yet, but we're making good progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc8f0f-c9fa-4f52-b5e7-26d2236e64ac",
   "metadata": {},
   "source": [
    "### Create a disk-shaped structuring element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1effc-a736-464f-8c82-bc85dbcfb1cb",
   "metadata": {},
   "source": [
    "We're getting the hang of this stuff! Let's now create a slightly more exciting image. We'll now write a short function to create a disk-shaped structuring element. Remember, structuring elements are actually just images too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f592b2-b594-4b66-8727-c7416a52f135",
   "metadata": {},
   "source": [
    "Write a function `make_disk_se(radius)` which takes an integer radius and returns a square image of `2*radius+1` rows and columns. The center of the disk is exactly the middle pixel of the image. The pixel intensities inside the disk are set to 1 and set to 0 everywhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c2db2-8ccf-481c-9db8-41de5681d19c",
   "metadata": {},
   "source": [
    "The easiest implementation approach is to first create an empty image of the right dimensions using the function `make_empty_image()` that you have implemented already, and then fill in the correct pixel values. To decide whether or not a pixel is inside the disk, you can use your `is_inside_disk(x, y, radius)` function too! Remember that the center of the disk is in the middle of the image, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d81df-4479-4d0b-bf4a-d3845c667d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def make_disk_se(radius):\n",
    "    # Create an empty image of the correct dimensions\n",
    "    height = _\n",
    "    width = _\n",
    "    img = make_empty_image(height, width)\n",
    "    \n",
    "    # Set pixels inside the disk to 1.\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            inside = is_inside_disk(_, _, _)\n",
    "            if inside:\n",
    "                _ = 1\n",
    "            else:\n",
    "                _ = 0  #  redundant, make_empty_image already did this\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61840899-ff2b-4453-bb55-b67b932a6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert make_disk_se(0) == [[1]], 'Expected: {[[1]]}, got: ' + str(make_disk_se(0))\n",
    "assert make_disk_se(1) == [[0, 1, 0], [1, 1, 1], [0, 1, 0]], 'Expected: {[[0, 1, 0], [1, 1, 1], [0, 1, 0]]}, got: ' + str(make_disk_se(1))\n",
    "assert make_disk_se(3) == [[0, 0, 0, 1, 0, 0, 0], [0, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 0], [0, 0, 0, 1, 0, 0, 0]], 'Expected: {[[0, 0, 0, 1, 0, 0, 0], [0, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 0], [0, 0, 0, 1, 0, 0, 0]]}, got: ' + str(make_disk_se(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32dbe2-e075-4b4e-aadd-3fd98518eca8",
   "metadata": {},
   "source": [
    "Let's see what a disk structuring element looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2a48d-ffff-4ff6-a150-2dd719be4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = make_disk_se(3)\n",
    "viz(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25157ae7-ed85-4266-81ca-09592033c857",
   "metadata": {},
   "source": [
    "Cool, that's a disk, no!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42f134-9937-4534-b97e-88dc44656d36",
   "metadata": {},
   "source": [
    "We're definitely on the right track here! Before we dig into the real meat of this project, we'll first implement two additional helper functions that deal with images and structuring elements: calculating the **complement** of an image, and **reflecting** a structuring element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f549f-b62c-40f6-bac8-433d736e85b8",
   "metadata": {},
   "source": [
    "### Image complement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be9f17-b887-48ba-ba1a-57f9fa78b150",
   "metadata": {},
   "source": [
    "The set-theoretical complement of an image or a structuring element $A$ is denoted $A^c$. We can view an image $A$ as a set of pixels (the black pixels, with value 1) that represents the *inside* of a certain 2-dimensional figure. The complement $A^c$ of that image then represents everything that is *outside* that figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1eb2dc-c223-4010-ae4a-a17870a891c5",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_image_complement.jpg\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa0269-05a1-45c2-adbd-a422c5c007d2",
   "metadata": {},
   "source": [
    "Calculating the complement of a binary image is easy: the complement image has pixels with value 0 where the input image has pixels with value 1, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71810867-7c5c-4a9e-8c41-ffc9ca46d835",
   "metadata": {},
   "source": [
    "Write a function `complement(img)` that returns a new image which is the complement of the input image `img`. Again the easiest approach if to first create an empty image of the correct dimensions (use your `get_image_dimensions()` function), and then iterate over the pixels to set the pixels in this new image to the correct value. Note that since structuring elements are also images, `complement` will work on them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdec65f-a477-495f-a453-b9c9d2390482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def complement(img):\n",
    "    # Make an empty image 'result' of the right dimensions\n",
    "    height, width = _\n",
    "    result = _\n",
    "    \n",
    "    # Now fill in the result with the correct pixel values\n",
    "    for i in range(_):\n",
    "        for j in range(_):\n",
    "            if img[i][j] == 0:\n",
    "                _\n",
    "            else:\n",
    "                _\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8ea88-7c4f-43f6-84a0-537f45437bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert complement([[0]]) == [[1]], 'Expected: {[[1]]}, got: ' + str(complement([[0]]))\n",
    "assert complement([[1]]) == [[0]], 'Expected: {[[0]]}, got: ' + str(complement([[1]]))\n",
    "assert complement([[1, 1, 0], [0, 1, 0]]) == [[0, 0, 1], [1, 0, 1]], 'Expected: {[[0, 0, 1], [1, 0, 1]]}, got: ' + str(complement([[1, 1, 0], [0, 1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583e77c-ca71-423f-b51d-283fd4ab088b",
   "metadata": {},
   "source": [
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c26ed-c91c-4df0-aeda-dfdfd53b7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 1, 0], \n",
    "       [0, 0, 1, 1, 0], \n",
    "       [0, 0, 0, 0, 0]]\n",
    "viz(img)\n",
    "viz(complement(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeabf51-73bf-47ab-a9f2-c9d016c12355",
   "metadata": {},
   "source": [
    "### Reflecting a structuring element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdcdbb-5f60-44f3-9acc-f7b05e6c8712",
   "metadata": {},
   "source": [
    "A second *helper* operation we need lateron is the reflection of a structuring element. Let's look into this now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e39a8-bcef-443e-bb15-65409871bd12",
   "metadata": {},
   "source": [
    "Suppose $B$ is a structuring element. The reflection of $B$, or the 180 degrees rotation of B around the origin, is denoted $\\breve{B}$ and defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390252b-f4ff-4ec0-815c-b84a3dbca61c",
   "metadata": {},
   "source": [
    "$$\\breve{B} = \\{-b : b \\in B\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8ea55-1be1-4bd5-94f8-95b11fe90f1f",
   "metadata": {},
   "source": [
    "This looks a bit scary but remember it just means to rotate the structuring element (image) around the origin, and by definition the origin of our structuring elements is always the middle pixel of the structuring element. In the example below, the original structuring element $B$ is the fish-like object on the left, and it's reflection $\\breve{B}$ is shown on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75067413-deea-4841-a3c5-62f93ae8c3be",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_se_reflection.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8aab44-d58c-4648-8f35-1ca9733a6880",
   "metadata": {},
   "source": [
    "We can now write the function `reflect_se(se)` which takes a structuring element (image) `se` as input, and returns a new structuring element (i.e. a new image) which is the reflection of `se`. Again, for simplicity start with an empty image of the correct dimensions, and fill in the correct pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab8b8e-9278-4001-8f25-254f34adc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def reflect_se(se):\n",
    "    # Make an empty image 'result' of the right dimensions\n",
    "    height, width = get_image_dimensions(se)\n",
    "    result = make_empty_image(height, width)\n",
    "    \n",
    "    # Structuring elements must have a center pixel, so their dimensions must be odd\n",
    "    assert height % 2 == 1\n",
    "    assert width % 2 == 1\n",
    "    \n",
    "    # Now fill in the result with the correct pixel values\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            result[i][j] = _\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9df04-acb2-4767-a2f3-f82fa7aa40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert reflect_se([[1]]) == [[1]], 'Expected: {[[1]]}, got: ' + str(reflect_se([[1]]))\n",
    "assert reflect_se([[0, 1, 1, 1, 1], [1, 0, 0, 0 ,0], [0, 1, 0, 1, 1]]) == [[1, 1, 0, 1, 0], [0, 0, 0, 0, 1], [1, 1, 1, 1, 0]], 'Expected: {[[0, 1, 0], [0, 0, 1], [0, 1, 1]]}, got: ' + str(reflect_se([[0, 1, 1, 1, 1], [1, 0, 0, 0 ,0], [0, 1, 0, 1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071256bd-9838-482a-8f26-7cd41e10c9d3",
   "metadata": {},
   "source": [
    "Let's see reflection in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01c928-60d8-413f-847e-f970f00412c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = [[0, 1, 1, 1, 1],\n",
    "      [1, 0, 0, 0 ,0],\n",
    "      [0, 1, 0, 1, 1]]\n",
    "viz(se)\n",
    "viz(reflect_se(se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a035fb53-8ac4-4c46-958c-e888163cbff4",
   "metadata": {},
   "source": [
    "### Erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c028e7-664f-4218-a267-3909d956b67b",
   "metadata": {},
   "source": [
    "We've now arrived at the crux of this project, implementing one of the core operations in mathematical morphology: erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139eee6c-674a-49b0-8ed5-a67128f747cf",
   "metadata": {},
   "source": [
    "In erosion we position the structuring element at each of the pixels in the input image in turn, and record whether or not the structuring element at that position fits inside the object represented by black pixels in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e2fae-c0ab-49f5-a306-111da75b3c84",
   "metadata": {},
   "source": [
    "In mathematical notation, the translation of a set $A$ by a point $x$ is denoted by $A_x$ and is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38fb7c6-e00a-417d-ad7c-8cbb0cc47391",
   "metadata": {},
   "source": [
    "$$ A_x = \\{a + x : a \\in A\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143bd892-95c5-4e70-8810-05cfacf9850b",
   "metadata": {},
   "source": [
    "Note that x is not just a single x-value, it is a 2D displacement (a 2D vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336d315-81f4-404e-a6ab-dd64c4ce2f2c",
   "metadata": {},
   "source": [
    "In the figure below, we have a structuring element (a) on the left, and its translation (b) on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefbc71-a6a7-4cf8-b911-bc66204b83ee",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_translation.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8665-068c-48c8-9615-ca163e0b40fb",
   "metadata": {},
   "source": [
    "The erosion of a set $A$ by a set $B$ is denoted $A \\ominus B$ and is defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334ca2c-8fb7-4f2e-ac54-0060deab439e",
   "metadata": {},
   "source": [
    "$$A \\ominus B = \\{ x : B_x \\subset A \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee777cbe-af4e-40fd-bb3f-ec006f3b10fc",
   "metadata": {},
   "source": [
    "In words, an image $A$ eroded by structuring element $B$ is the set of all translations $x$ (the set of all positions in the input image) such that when we position the structuring element at that location, the structuring element is a subset $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543857c-6208-4ddc-8502-38e520057abf",
   "metadata": {},
   "source": [
    "In the figure below in (a) the input image is shown in gray, and its erosion in black. The structuring element used is shown in (b). Note that the erosion indicates all the places where the structuring element can be placed so that it remains inside the gray input image (object)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b60515-d959-441b-8ee6-7df6b8efaac5",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_erosion.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6153-3734-43aa-bbde-327d7342975e",
   "metadata": {},
   "source": [
    "Let's now implement erosion! We will break the implementation in two: one part is to position the structuring element over each of the pixels in the input image in turn, and the other is to check whether the structuring element placed at that position 'fits' inside the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd271c-9f3f-4cda-80a2-f2ebcb6ff674",
   "metadata": {},
   "source": [
    "Write a function `is_subset(img, se, translation)` where `img` is the input image, `se` is a structuring element (which is also an image), and `translation` is a pair of values (row, column) that indicate the pixel in the input image on which to center the structuring element. The function then compares all pixels in the structuring element with the corresponding pixels in the input image. If **no** black (value 1) pixels in the structuring element overlap with empty (value 0) pixels in the input image, the structuring element 'fits' in the image at that position, and `is_subset` returns True, otherwise it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bd570-07e8-4e17-b145-dabcef67a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def is_subset(img, se, translation):\n",
    "    # Get the dimensions of the input image\n",
    "    img_height, img_width = get_image_dimensions(img)\n",
    "    \n",
    "    # Get the dimensions of the structuring element\n",
    "    se_height, se_width = get_image_dimensions(se)\n",
    "    \n",
    "    # Unpack the translation pair into ti, tj (i.e. image row, image column)\n",
    "    ti, tj = _\n",
    "    \n",
    "    # The *center* of the structuring element \n",
    "    # (= the middle pixel of the structuring element)\n",
    "    # must be placed on the image at position (ti, tj).\n",
    "    \n",
    "    # Iterate over each pixel in the structuring element.\n",
    "    # Translate it and compare it to the pixel in the input image at that location,\n",
    "    # to see if we can conclude that the structuring element is not a subset.\n",
    "    # Note also that some pixels in the structuring element might stick outside\n",
    "    # the input image. We need to check for this and ignore such pixels.\n",
    "    for i in range(se_height):\n",
    "        for j in range(se_width):\n",
    "            row = _\n",
    "            col = _\n",
    "            if row >= 0 and col >= 0 and _ and _:\n",
    "                if img[row][col] == _ and se[i][j] == _:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852f74b-5987-4715-b875-d00aa9b5bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 1, 0], \n",
    "       [0, 0, 1, 1, 0], \n",
    "       [0, 0, 0, 0, 0]]\n",
    "se = [[0, 0, 0],\n",
    "      [1, 1, 0],\n",
    "      [0, 1, 0]]\n",
    "assert is_subset([[1]], [[1]], (0, 0)) == True\n",
    "assert is_subset([[0]], [[1]], (0, 0)) == False\n",
    "assert is_subset(img, se, (0, 0)) == False, 'Expected: False, got: ' + str(is_subset(img, se, (0, 0)))\n",
    "assert is_subset(img, se, (1, 2)) == True, 'Expected: True, got: ' + str(is_subset(img, se, (1, 2)))\n",
    "assert is_subset(img, se, (1, 3)) == True, 'Expected: True, got: ' + str(is_subset(img, se, (1, 3)))\n",
    "assert is_subset(img, se, (3, 4)) == False, 'Expected: False, got: ' + str(is_subset(img, se, (3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbda77-668d-42fc-9ea1-e6572fba9697",
   "metadata": {},
   "source": [
    "The actual erosion function is now straightforward. Write a function `erode_image(img, se)` which loops over all pixels in the input image `img` and checks whether a structuring element at that position is a subset of `img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a352ef-3bf0-465c-8035-aec4ee61f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def erode_image(img, se):\n",
    "    # Create an empty result image of the correct dimensions\n",
    "    height, width = get_image_dimensions(img)\n",
    "    result = make_empty_image(height, width)\n",
    "    \n",
    "    # Position the structuring element over each of the pixels\n",
    "    # in the input image in turn, and remember in\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            translation = _  # the translation position is a pair of image coordinates\n",
    "            if is_subset(_, _, _):\n",
    "                result[i][j] = _\n",
    "            else:\n",
    "                result[i][j] = _\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e5cad-4787-452e-aa6a-912e1575dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[0, 0, 0, 0, 0],\n",
    "       [0, 1, 1, 1, 0], \n",
    "       [0, 0, 1, 1, 0], \n",
    "       [0, 0, 0, 0, 0]]\n",
    "se = [[0, 0, 0],\n",
    "      [1, 1, 0],\n",
    "      [0, 1, 0]]\n",
    "assert erode_image(img, se) == [[0, 0, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'Expected: {[[0, 0, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]}, got: ' + str(erode_image(img, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c571e-a55a-4612-8dc2-3df7c9e94583",
   "metadata": {},
   "source": [
    "That was a bit hairy! But we've finished the hardest part. The rest of the project is mostly assembling the building blocks we've implemented already. I promise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d5307-d7ee-4335-a65a-efe1e8497cc7",
   "metadata": {},
   "source": [
    "### Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf5887-1eec-47dd-be7d-1fcbfdd8fa01",
   "metadata": {},
   "source": [
    "The next morphological operation we need is dilation. In a sense it is \"the opposite\" (the dual) of erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bda177-b7aa-4675-9623-951f3df817ba",
   "metadata": {},
   "source": [
    "The figure below shows dilation as the dual of erosion (dilation as expansion). Shown on the left (a) is the input image in black, and its dilation in gray. On the right (b) is the structuring element used for the dilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3bde1-4871-4ac0-9914-dfb9835003a7",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_dilation.png\" width=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c769d5c-ddbb-4b62-91ce-917c52b248ff",
   "metadata": {},
   "source": [
    "The dilation of $A$ by $B$ is denoted $A \\oplus B$ and is defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2ec25-92d0-44b6-9a37-fc2bd41dbfdb",
   "metadata": {},
   "source": [
    "$$ A \\oplus B = (A^c \\ominus \\breve{B})^c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c4f77-e701-4051-908a-15a94c344985",
   "metadata": {},
   "source": [
    "where $A^c$ denotes the complement of A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b745f-15d6-44b4-80e0-2dd541db4c64",
   "metadata": {},
   "source": [
    "To dilate $A$ by $B$, $B$ is reflected (i.e. rotated around the origin) to obtain $\\breve{B}$, $A^c$ is eroded by $\\breve{B}$, and then the complement of the erosion is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301df018-c36c-40f3-a341-0c1dada0f88e",
   "metadata": {},
   "source": [
    "Because of all our hard preliminary work, implementing dilation is now trivial! Write a function `dilate_image(img, se)` which takes an input image `img` that must be dilated by structuring element `se`, and which returns the resulting dilated image. The implementation is simply the composition of a couple of functions you defined earlier in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e16ee-147b-4691-a1c9-fdf75f6d0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def dilate_image(img, se):\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75483fdb-6374-4865-ba36-5e73b91d8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[1, 0, 1, 0, 0],\n",
    "       [0, 1, 1, 1, 0], \n",
    "       [0, 0, 1, 1, 0], \n",
    "       [1, 1, 1, 1, 0], \n",
    "       [0, 0, 1, 1, 0]]\n",
    "se = [[0, 0, 0],\n",
    "      [1, 1, 0],\n",
    "      [0, 1, 0]]\n",
    "assert dilate_image([[1]], [[1]]) == [[1]], 'Expected: {[[1]]}, got: ' + str(dilate_image([[1]], [[1]]))\n",
    "assert dilate_image(img, se) == [[1, 1, 1, 0, 0],[1, 1, 1, 1, 0], [0, 1, 1, 1, 0],[1, 1, 1, 1, 0], [1, 1, 1, 1, 0]], 'Expected: {[[1, 1, 1, 0, 0],[1, 1, 1, 1, 0], [0, 1, 1, 1, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0]]}, got: ' + str(erode_image(img, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd119b5-29db-4629-aaee-114b145e1525",
   "metadata": {},
   "source": [
    "### Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15d08f-7894-43cf-8d7d-00262e22b03d",
   "metadata": {},
   "source": [
    "Finally, we arrive at the last morphological operation that we need to implement: *closing*. It is defined as a dilation followed by an erosion with the same structuring element. The idea is that dilation first fills in small holes and indentations in an image, but also tends to grow the image towards the outside. By following dilation with erosion, the indentations remain filled, but we \"undo\" the general outward growth of the image. We will use closing as a core component in the segmentation algorithm in Part 3 of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80339f-b0fc-40ec-9831-4c6d0cd16cc5",
   "metadata": {},
   "source": [
    "In the figure below: (a) disk structuring element, (b) input image, (c) dilation, (d) closing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70635bf3-4458-4a7e-9816-7b95357c318e",
   "metadata": {},
   "source": [
    "<center><img src=\"images/segm_dilation_vs_closing.png\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291358c-4902-4c28-b8f0-cd16cb66d6f3",
   "metadata": {},
   "source": [
    "In mathematical notation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b36914a-c0fe-4885-a6e9-a0185a969937",
   "metadata": {},
   "source": [
    " The **closing** of A by B is denoted by $A \\bullet B$ and is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfc74b-a25e-49e1-bc4c-9081e405a06c",
   "metadata": {},
   "source": [
    "$$A \\bullet B = (A \\oplus B) \\ominus B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d1de05-6518-44d4-a569-a18f8fa58147",
   "metadata": {},
   "source": [
    "The implementation of closing is once again trivial given the building blocks we already implemented. Write a function `close_image(img, se)` which implements closing by first dilating the image and then eroding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335c384-1174-4ca6-87ac-2672d8dd555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def close_image(img, se):\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754c90f-25ae-44e5-b4ae-f0e0b694dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[0,0,0,0,0,0],\n",
    "       [0,1,0,1,0,0],\n",
    "       [0,1,1,0,1,0],\n",
    "       [0,1,1,1,0,0],\n",
    "       [0,0,0,0,0,0]]\n",
    "se = [[0,0,0],\n",
    "      [0,1,0],\n",
    "      [0,1,1]]\n",
    "assert close_image(img, se) == [[0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 1, 0], [0, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 0]], 'Expected: {[[0, 0, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0], [0, 1, 1, 1, 1, 0], [0, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 0]]}, got: ' + str(close_image(img, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a9eec-2d52-41ae-9145-b9261d12de13",
   "metadata": {},
   "source": [
    "The fact that these implementations are simple compositions of other functions is not coincidental, but a direct consequence of the fact that these morphological operations form an algebra with an elegant and clearly defined mathematical structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0cde96-d746-4c01-a800-922a1373f014",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comparing erosion, dilation and closing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e68cdf-fc36-4f32-8dee-fb0898b83eb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "As an example of erosion, dilation and closing, let's have a look what these operations have as effect on the image of a letter g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc1058-a3cd-42d5-bb41-ad381bc31adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A letter g\n",
    "img = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       [0,0,0,0,1,1,1,1,1,1,0,1,1,0,0],\n",
    "       [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0],\n",
    "       [0,0,1,1,1,0,0,0,1,1,1,1,0,0,0],\n",
    "       [0,0,1,1,0,0,0,0,0,1,1,0,0,0,0],\n",
    "       [0,0,1,1,1,0,0,0,0,1,1,1,0,0,0],\n",
    "       [0,0,1,1,1,1,0,0,1,1,1,1,0,0,0],\n",
    "       [0,0,0,1,1,1,1,1,1,1,1,0,0,0,0],\n",
    "       [0,0,1,1,0,1,1,1,1,1,0,0,0,0,0],\n",
    "       [0,0,1,1,1,0,0,0,0,0,0,0,0,0,0],\n",
    "       [0,0,1,1,1,1,1,1,1,1,1,1,0,0,0],\n",
    "       [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0],\n",
    "       [0,0,1,1,1,0,0,0,0,1,1,1,1,0,0],\n",
    "       [0,0,1,1,0,0,0,0,0,0,0,1,1,0,0],\n",
    "       [0,0,1,1,0,0,0,0,0,0,1,1,1,0,0],\n",
    "       [0,0,1,1,1,1,0,0,0,1,1,1,1,0,0],\n",
    "       [0,0,0,0,1,1,1,1,1,1,1,0,0,0,0],\n",
    "       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "       [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "       \n",
    "se = [[0, 1, 0],\n",
    "      [1, 1, 1],\n",
    "      [0, 1, 0]]\n",
    "\n",
    "viz(se)\n",
    "viz(img)\n",
    "viz(erode_image(img, se))\n",
    "viz(dilate_image(img, se))\n",
    "viz(close_image(img, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14fc0a5-4496-449b-93de-497f03fa00bf",
   "metadata": {},
   "source": [
    "Note how dilation filled the small hole and the groove between the top and bottom halves of the letter g, but also made the letter thicker. The closing operation closed these gaps too, but leaves the letter roughly the same thickness.\n",
    "\n",
    "It is for this behaviour that we will use the *closing* morphological filter operation to merge nearby metal precipitates in our Golgi stained images into larger blobs (approximately) corresponding to the shape of the neurons that they stain.\n",
    "\n",
    "We now have all the tools for tackling our original problem: image segmentation. Let's move on to part 3 of the project!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6006ae-501a-48ad-ba70-734d0222ecc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd05ed-867e-4838-81c6-afc6a68c29f2",
   "metadata": {},
   "source": [
    "## Part 3: Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585e24e-f083-4c55-9e8b-4fc9d6434de5",
   "metadata": {},
   "source": [
    "In the last part of the project we will perform the actual segmentation of the electron microscopy image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1271bd3-6fed-4f80-ae20-0050edb7825a",
   "metadata": {},
   "source": [
    "We need one final helper function, which we already alluded to in Part 1: a function for thresholding a grayscale image into a binary image. Let's get that out of the way first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7fc19f-9920-4ece-98d4-e3f0d384dd9b",
   "metadata": {},
   "source": [
    "### Thresholding a grayscale image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec55aff-ff0f-48f2-a370-f1652ddf5924",
   "metadata": {},
   "source": [
    "Write a function `threshold_grayscale_image(img, threshold)` which takes a grayscale image `img` and a `threshold` pixel intensity value, and returns a binary image that has black pixels (=value 1) whenever the corresponding pixel in the input `img` has a pixel intensity strictly below `threshold`. The general approach for implementing this function is very similar to several functions in previous assignments in Part 2, so we've left the complete function body as an exercise for you.\n",
    "\n",
    "Feel free to use (or not use) the function `is_below()` which you wrote in Part 1 of the project to perform the comparison between a pixel intensity and the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140f16ac-5cc2-40bc-9684-e0a9481b31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "def threshold_grayscale_image(img, threshold):\n",
    "    # Construct an empty image of the right dimensions\n",
    "    _\n",
    "    \n",
    "    # Iterate over all pixels in img,\n",
    "    # compare the pixel value with threshold,\n",
    "    # and set the corresponding pixel in the output image\n",
    "    # to the correct value.\n",
    "    _\n",
    "            \n",
    "    return _"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1168cb74-4cca-48a4-97d0-b008eb399c48",
   "metadata": {},
   "source": [
    "Run a quick test to see if thresholding an image works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8026bc-786b-451f-9aaf-b82bae5e1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a function for reading grayscale images into our list of list representation.\n",
    "from solutions.segmentation import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bffb7e-679a-4094-8ffc-b2e0d65aaa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell checks a couple of pixels to see if thresholding was implemented correctly\n",
    "golgi = read_image('images/golgi-crop.png')\n",
    "golgi_thresholded = threshold_grayscale_image(golgi, 10)\n",
    "assert golgi_thresholded[41][100:120] == [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], 'Expected: {[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}, got: ' + str(golgi_thresholded[41][100:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20c051-e452-421c-acb5-0a47e0d83b80",
   "metadata": {},
   "source": [
    "You've implemented all the building blocks now, they just need to be glued together now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb2588-cefe-4917-8630-bcd915503fcd",
   "metadata": {},
   "source": [
    "### It's image segmentation time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102020e6-9eed-4955-ae1b-bc1a8ff81ff3",
   "metadata": {},
   "source": [
    "Time for the last assignment in this project. Write a function `segment_golgi_stained_image(img, threshold1, closing_size, box_filter_half_width, threshold2)` which takes a grayscale Golgi stained electron microscopy image `img` as input and returns a binary segmentation result. \n",
    "\n",
    "The function `segment_golgi_stained_image()` will transform the input image `img` step by step by performing the following operations in sequence:\n",
    "1. Threshold the grayscale input image using the parameter `threshold1`.\n",
    "2. Construct a disk-shaped structuring element of size `closing_size`.\n",
    "3. Perform morphological closing on the thresholded image from step 1, using the structuring element from step 2.\n",
    "4. Smoothen the closed image from step 3 by applying a box filter to it. (The box filter takes the binary image as input, and creates a new image where each pixel is the average of all pixels in a square box around the corresponding pixel in the input image. This has the effect of smoothening the boundary of the segmentation. The box filtered image is again a grayscale image. You can use the function `box_filter_image(closed image, box_filter_half_width)` which we provided.)\n",
    "5. Threshold the box filtered image using the parameter `threshold2`.\n",
    "6. This final tresholded image is the binary segmentation of the input image; return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b955ca-68f4-4bce-8375-61ff42c0d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "from solutions.segmentation import box_filter_image\n",
    "\n",
    "def segment_golgi_stained_image(img, threshold1, closing_size, box_filter_half_width, threshold2):\n",
    "    # Threshold the grayscale image img into a binary image using threshold value 'threshold1'.\n",
    "    _\n",
    "    \n",
    "    # Construct a disk shaped structuring element of size 'closing_size'.\n",
    "    _\n",
    "    \n",
    "    # Perform the closing operation on the thresholded image.\n",
    "    _\n",
    "    \n",
    "    # Smoothen the closed image using a box filter of size 'box_filter_half_width'.\n",
    "    _ = box_filter_image(_, box_filter_half_width)\n",
    "    \n",
    "    # Threshold the smoothed image once again into a binary image, using threshold2.\n",
    "    # This binary image is our segmentation.\n",
    "    _\n",
    "    \n",
    "    # Return the segmentation.\n",
    "    return _"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c57e86-7408-4242-904a-fcf52631bb2c",
   "metadata": {},
   "source": [
    "There are no asserts to check your code, but the proof of the pudding is in the eating, so let's run it on the actual data now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec903cb1-a190-4096-a9d9-b2c3a752e91e",
   "metadata": {},
   "source": [
    " There are a couple of parameters in the algorithm, and they have a significant effect on the result, so they need some manual tuning. The values below produce a reasonable segmentation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f35fb-fa11-40fc-a6e6-f225da3e6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold1 = 90  # measured manually on the dense staining particles, for example using Image/Fiji.\n",
    "closing_size = 12\n",
    "box_filter_half_width = 6\n",
    "threshold2 = 220\n",
    "\n",
    "golgi = read_image('images/golgi-crop.png')\n",
    "segmented_golgi = segment_golgi_stained_image(golgi, threshold1, closing_size, box_filter_half_width, threshold2)\n",
    "\n",
    "viz(golgi, is_binary=False, show_pixel_edges=False)\n",
    "viz(segmented_golgi, show_pixel_edges=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7a35b-4f31-4816-b05d-16bede5c6bf5",
   "metadata": {},
   "source": [
    "We can also display the original image with the segmentation mask transparently on top, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf55e52-8b38-4117-b22c-d4d82a4d5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(golgi, 'gray', interpolation='none')\n",
    "plt.imshow(segmented_golgi, 'cool', interpolation='none', alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db3f18-e9d9-46da-9089-3c74b61d51d6",
   "metadata": {},
   "source": [
    "Finally, below we show the images generated by the different processing steps in the algorithm. From top to bottom, left to right: the input image; the thresholded image with the dense metal precipitate, the closed version with the precipitate joined into a contiguous region, the box filtered version of this showing are more smooth boundary; the thresholded version of this which is the actual segmentation result; and an overlay showing the input EM image and the segmentation mask on top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e21bb-5282-4171-8465-e775f6477860",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/segm_result_a_input.png\" width=\"150\"/>\n",
    "<img src=\"images/segm_result_b_stain.png\" width=\"150\"/>\n",
    "<img src=\"images/segm_result_c_closed.png\" width=\"150\"/>\n",
    "<img src=\"images/segm_result_d_box_filtered.png\" width=\"150\"/>\n",
    "<img src=\"images/segm_result_e_mask.png\" width=\"150\"/>\n",
    "<img src=\"images/segm_result_f_overlay.png\" width=\"150\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6869bf0f-d4c5-45f8-b978-3b51706bf066",
   "metadata": {},
   "source": [
    "Congratulations for making it this far! It's been a wild ride, but you can be proud of what you accomplished. You've implemented a non-trivial image processing pipeline with your bare hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f967ae9-c4f0-45c8-94e2-9fc9e18a5504",
   "metadata": {},
   "source": [
    "Good luck with your future programming endeavors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90842202-ca95-4d9d-8250-8b923e6dbdde",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b47ae0-a54c-4b4a-a59f-2e75280933cd",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fe4c4-3e04-40d8-96b9-c7f10611e6ea",
   "metadata": {},
   "source": [
    "Book: *Hands-on Morphological Image Processing*, Edward R. Dougherty, Roberto A. Lotufo, 2003"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c09691-9a0b-448c-8dcb-eb8618e15109",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
